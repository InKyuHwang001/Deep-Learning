{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13.과적합 피하기.ipynb","provenance":[],"collapsed_sections":["HJeof3Vrhyz6","txyx3ksYiNUP","GFo-nJ6jiOmB","LF-7WV0kiQDF"],"mount_file_id":"1lqSqnClorENrhQ3Ng_lp9ymFbUZxeB1D","authorship_tag":"ABX9TyNDwxXnkxRGa0NcRcmplrl/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1.데이터의 확인과 실행\n"],"metadata":{"id":"HJeof3Vrhyz6"}},{"cell_type":"markdown","source":["- 실습 데이터 초음파 광물 예측"],"metadata":{"id":"puZgtHrPiSAV"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","my_data = 'sonar.csv'"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":76},"id":"gaju6thAighB","executionInfo":{"status":"ok","timestamp":1647146083283,"user_tz":-540,"elapsed":13989,"user":{"displayName":"황인규","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00970641099625056923"}},"outputId":"fd031391-b28f-4ff5-9591-519f15724b1f"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-1751e649-57c6-45fc-9ee4-a6622d22aa62\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-1751e649-57c6-45fc-9ee4-a6622d22aa62\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving sonar.csv to sonar (2).csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(my_data, header=None)\n","print(df.info())\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pc1oKnTCi7GK","executionInfo":{"status":"ok","timestamp":1647146084390,"user_tz":-540,"elapsed":8,"user":{"displayName":"황인규","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00970641099625056923"}},"outputId":"720a90ab-ef43-4c4a-c482-8519811a4902"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 208 entries, 0 to 207\n","Data columns (total 61 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   0       208 non-null    float64\n"," 1   1       208 non-null    float64\n"," 2   2       208 non-null    float64\n"," 3   3       208 non-null    float64\n"," 4   4       208 non-null    float64\n"," 5   5       208 non-null    float64\n"," 6   6       208 non-null    float64\n"," 7   7       208 non-null    float64\n"," 8   8       208 non-null    float64\n"," 9   9       208 non-null    float64\n"," 10  10      208 non-null    float64\n"," 11  11      208 non-null    float64\n"," 12  12      208 non-null    float64\n"," 13  13      208 non-null    float64\n"," 14  14      208 non-null    float64\n"," 15  15      208 non-null    float64\n"," 16  16      208 non-null    float64\n"," 17  17      208 non-null    float64\n"," 18  18      208 non-null    float64\n"," 19  19      208 non-null    float64\n"," 20  20      208 non-null    float64\n"," 21  21      208 non-null    float64\n"," 22  22      208 non-null    float64\n"," 23  23      208 non-null    float64\n"," 24  24      208 non-null    float64\n"," 25  25      208 non-null    float64\n"," 26  26      208 non-null    float64\n"," 27  27      208 non-null    float64\n"," 28  28      208 non-null    float64\n"," 29  29      208 non-null    float64\n"," 30  30      208 non-null    float64\n"," 31  31      208 non-null    float64\n"," 32  32      208 non-null    float64\n"," 33  33      208 non-null    float64\n"," 34  34      208 non-null    float64\n"," 35  35      208 non-null    float64\n"," 36  36      208 non-null    float64\n"," 37  37      208 non-null    float64\n"," 38  38      208 non-null    float64\n"," 39  39      208 non-null    float64\n"," 40  40      208 non-null    float64\n"," 41  41      208 non-null    float64\n"," 42  42      208 non-null    float64\n"," 43  43      208 non-null    float64\n"," 44  44      208 non-null    float64\n"," 45  45      208 non-null    float64\n"," 46  46      208 non-null    float64\n"," 47  47      208 non-null    float64\n"," 48  48      208 non-null    float64\n"," 49  49      208 non-null    float64\n"," 50  50      208 non-null    float64\n"," 51  51      208 non-null    float64\n"," 52  52      208 non-null    float64\n"," 53  53      208 non-null    float64\n"," 54  54      208 non-null    float64\n"," 55  55      208 non-null    float64\n"," 56  56      208 non-null    float64\n"," 57  57      208 non-null    float64\n"," 58  58      208 non-null    float64\n"," 59  59      208 non-null    float64\n"," 60  60      208 non-null    object \n","dtypes: float64(60), object(1)\n","memory usage: 99.2+ KB\n","None\n","       0       1       2       3       4       5       6       7       8   \\\n","0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n","1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n","2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n","3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n","4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n","\n","       9   ...      51      52      53      54      55      56      57  \\\n","0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n","1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n","2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n","3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n","4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n","\n","       58      59  60  \n","0  0.0090  0.0032   R  \n","1  0.0052  0.0044   R  \n","2  0.0095  0.0078   R  \n","3  0.0040  0.0117   R  \n","4  0.0107  0.0094   R  \n","\n","[5 rows x 61 columns]\n"]}]},{"cell_type":"code","source":["# # 데이터 입력\n","# from google.colab import files\n","# uploaded = files.upload()\n","# my_data = 'sonar.csv'\n","\n","# # 본문에 맞는 텐서플로 버전을 선택\n","# !pip install -q tensorflow-gpu==1.15.0\n","# %tensorflow_version 1.x\n","\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from sklearn.preprocessing import LabelEncoder\n","\n","# seed 값 설정\n","np.random.seed(42)\n","tf.compat.v1.set_random_seed(42)\n","\n","#데이터 적용\n","df = pd.read_csv(my_data, header=None)\n","\n","\n","# 데이터를 넘파이 배열로 변환 및 타겟 분리\n","dataset = df.values\n","X= dataset[:,:-1].astype(float) # 타입이 object라서 float로 바꿔줘야함\n","y= dataset[:,-1]\n","\n","# 문자열 변환\n","le = LabelEncoder()\n","le.fit(y)\n","y = le.transform(y)\n","\n","# 모델 설정\n","model = Sequential()\n","model.add(Dense(24,  input_dim=60, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 모델 컴파일\n","model.compile(loss='mean_squared_error',\n","            optimizer='adam',\n","            metrics=['accuracy'])\n","\n","# 모델 실행\n","model.fit(X, y, epochs=200, batch_size=5)\n","\n","# 결과 출력\n","print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNu1yjqljwiZ","executionInfo":{"status":"ok","timestamp":1647146731178,"user_tz":-540,"elapsed":22136,"user":{"displayName":"황인규","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00970641099625056923"}},"outputId":"47414b4d-c304-4445-c10a-fed51c7773f1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","42/42 [==============================] - 1s 3ms/step - loss: 0.2356 - accuracy: 0.5337\n","Epoch 2/200\n","42/42 [==============================] - 0s 3ms/step - loss: 0.2225 - accuracy: 0.5673\n","Epoch 3/200\n","42/42 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.6442\n","Epoch 4/200\n","42/42 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.7019\n","Epoch 5/200\n","42/42 [==============================] - 0s 4ms/step - loss: 0.2001 - accuracy: 0.7692\n","Epoch 6/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.7692\n","Epoch 7/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.7596\n","Epoch 8/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.7981\n","Epoch 9/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.7981\n","Epoch 10/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.8125\n","Epoch 11/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.8317\n","Epoch 12/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.8029\n","Epoch 13/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.8365\n","Epoch 14/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.8173\n","Epoch 15/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.8173\n","Epoch 16/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.8413\n","Epoch 17/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.7933\n","Epoch 18/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.8365\n","Epoch 19/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.8125\n","Epoch 20/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.8365\n","Epoch 21/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.8510\n","Epoch 22/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.8413\n","Epoch 23/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.8413\n","Epoch 24/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.8558\n","Epoch 25/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.8654\n","Epoch 26/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.8654\n","Epoch 27/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.8894\n","Epoch 28/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.8846\n","Epoch 29/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.8702\n","Epoch 30/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9038\n","Epoch 31/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.8606\n","Epoch 32/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.8990\n","Epoch 33/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.8894\n","Epoch 34/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.8846\n","Epoch 35/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.8894\n","Epoch 36/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9087\n","Epoch 37/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9038\n","Epoch 38/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9087\n","Epoch 39/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.8990\n","Epoch 40/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9135\n","Epoch 41/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9135\n","Epoch 42/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9038\n","Epoch 43/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.8990\n","Epoch 44/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9231\n","Epoch 45/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9135\n","Epoch 46/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.8798\n","Epoch 47/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9279\n","Epoch 48/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9135\n","Epoch 49/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9279\n","Epoch 50/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9423\n","Epoch 51/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9231\n","Epoch 52/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9135\n","Epoch 53/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9038\n","Epoch 54/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9375\n","Epoch 55/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9375\n","Epoch 56/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9375\n","Epoch 57/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9423\n","Epoch 58/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9375\n","Epoch 59/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9471\n","Epoch 60/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9327\n","Epoch 61/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9471\n","Epoch 62/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9375\n","Epoch 63/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9327\n","Epoch 64/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9279\n","Epoch 65/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9327\n","Epoch 66/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9327\n","Epoch 67/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9519\n","Epoch 68/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9519\n","Epoch 69/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9615\n","Epoch 70/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9471\n","Epoch 71/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9519\n","Epoch 72/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9423\n","Epoch 73/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9471\n","Epoch 74/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9519\n","Epoch 75/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9471\n","Epoch 76/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9423\n","Epoch 77/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9519\n","Epoch 78/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9567\n","Epoch 79/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9519\n","Epoch 80/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9615\n","Epoch 81/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9663\n","Epoch 82/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9615\n","Epoch 83/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9615\n","Epoch 84/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9615\n","Epoch 85/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9615\n","Epoch 86/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9615\n","Epoch 87/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9663\n","Epoch 88/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9567\n","Epoch 89/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9712\n","Epoch 90/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9808\n","Epoch 91/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9808\n","Epoch 92/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9712\n","Epoch 93/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9808\n","Epoch 94/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9712\n","Epoch 95/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9615\n","Epoch 96/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9856\n","Epoch 97/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9663\n","Epoch 98/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9663\n","Epoch 99/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9760\n","Epoch 100/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9760\n","Epoch 101/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9760\n","Epoch 102/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9760\n","Epoch 103/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9760\n","Epoch 104/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9712\n","Epoch 105/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9856\n","Epoch 106/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9663\n","Epoch 107/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9856\n","Epoch 108/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9808\n","Epoch 109/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9904\n","Epoch 110/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9856\n","Epoch 111/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9904\n","Epoch 112/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9808\n","Epoch 113/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9760\n","Epoch 114/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9615\n","Epoch 115/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9856\n","Epoch 116/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9856\n","Epoch 117/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9856\n","Epoch 118/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9808\n","Epoch 119/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9952\n","Epoch 120/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9904\n","Epoch 121/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9904\n","Epoch 122/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9952\n","Epoch 123/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9856\n","Epoch 124/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9952\n","Epoch 125/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9952\n","Epoch 126/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9952\n","Epoch 127/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9904\n","Epoch 128/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9904\n","Epoch 129/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9952\n","Epoch 130/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9856\n","Epoch 131/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9904\n","Epoch 132/200\n","42/42 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9952\n","Epoch 133/200\n","42/42 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9952\n","Epoch 134/200\n","42/42 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9952\n","Epoch 135/200\n","42/42 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9952\n","Epoch 136/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9952\n","Epoch 137/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9952\n","Epoch 138/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9904\n","Epoch 139/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9904\n","Epoch 140/200\n","42/42 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9952\n","Epoch 141/200\n","42/42 [==============================] - 0s 7ms/step - loss: 0.0116 - accuracy: 0.9952\n","Epoch 142/200\n","42/42 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9952\n","Epoch 143/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9952\n","Epoch 144/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9952\n","Epoch 145/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9904\n","Epoch 146/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9952\n","Epoch 147/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9952\n","Epoch 148/200\n","42/42 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9952\n","Epoch 149/200\n","42/42 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9952\n","Epoch 150/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9952\n","Epoch 151/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9952\n","Epoch 152/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9952\n","Epoch 153/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9952\n","Epoch 154/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9952\n","Epoch 155/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9952\n","Epoch 156/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9952\n","Epoch 157/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9952\n","Epoch 158/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9952\n","Epoch 159/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9952\n","Epoch 160/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9952\n","Epoch 161/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9952\n","Epoch 162/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9952\n","Epoch 163/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9952\n","Epoch 164/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9952\n","Epoch 165/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9952\n","Epoch 166/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9952\n","Epoch 167/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9952\n","Epoch 168/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9952\n","Epoch 169/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9952\n","Epoch 170/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9952\n","Epoch 171/200\n","42/42 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9952\n","Epoch 172/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9952\n","Epoch 173/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9952\n","Epoch 174/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9952\n","Epoch 175/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9952\n","Epoch 176/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9952\n","Epoch 177/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9952\n","Epoch 178/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9952\n","Epoch 179/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9952\n","Epoch 180/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9952\n","Epoch 181/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9952\n","Epoch 182/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9952\n","Epoch 183/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9952\n","Epoch 184/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9952\n","Epoch 185/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9952\n","Epoch 186/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9952\n","Epoch 187/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9952\n","Epoch 188/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9952\n","Epoch 189/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9952\n","Epoch 190/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9952\n","Epoch 191/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9952\n","Epoch 192/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9952\n","Epoch 193/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9952\n","Epoch 194/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9952\n","Epoch 195/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9952\n","Epoch 196/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9952\n","Epoch 197/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9952\n","Epoch 198/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9952\n","Epoch 199/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9952\n","Epoch 200/200\n","42/42 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9952\n","7/7 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9952\n","\n"," Accuracy: 0.9952\n"]}]},{"cell_type":"markdown","source":["# 2.과적합 이해하기\n"],"metadata":{"id":"9QmZQxWwiLGv"}},{"cell_type":"markdown","source":["- 과적합은 층이 너무 많거나 변수가 복잡해서 발생\n","- test와 train 셋이 중복시 발생\n"],"metadata":{"id":"_3MsdQpLlHob"}},{"cell_type":"markdown","source":["# 3.학습셋과 테스트셋\n"],"metadata":{"id":"txyx3ksYiNUP"}},{"cell_type":"markdown","source":["- 과적합 방지 방법\n","  - 테스트 데이터와 학습 데이터를 분리\n","- 학습데이터만으로 평가 할시 에포크 값을 높이거나 층을 더하면 정확도가 올라감"],"metadata":{"id":"AySUmZ1umiMH"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train,X_test,y_train, y_test=train_test_split(X,y, test_size=0.3, random_state=42)\n","model.fit(X_train, y_train,epochs=130,batch_size=5)\n","print(f'Total Accuracy : {accuracy}')"],"metadata":{"id":"z0EqZhfknU5O","executionInfo":{"status":"ok","timestamp":1647147165659,"user_tz":-540,"elapsed":5,"user":{"displayName":"황인규","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00970641099625056923"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 데이터 입력\n","#from google.colab import files\n","#uploaded = files.upload()\n","#my_data = 'sonar.csv'\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy\n","import tensorflow as tf\n","\n","# seed 값 설정\n","seed = 0\n","numpy.random.seed(seed)\n","tf.compat.v1.set_random_seed(3)\n","\n","#데이터 적용\n","df = pd.read_csv(my_data, header=None)\n","\n","'''\n","print(df.info())\n","print(df.head())\n","'''\n","\n","dataset = df.values\n","X = dataset[:,0:-1].astype(float)\n","Y_obj = dataset[:,-1]\n","\n","e = LabelEncoder()\n","e.fit(Y_obj)\n","Y = e.transform(Y_obj)\n","\n","# 학습 셋과 테스트 셋의 구분\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n","\n","model = Sequential()\n","model.add(Dense(24,  input_dim=60, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='mean_squared_error',\n","            optimizer='adam',\n","            metrics=['accuracy'])\n","\n","model.fit(X_train, Y_train, epochs=130, batch_size=5)\n","\n","# 테스트셋에 모델 적용\n","print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KacYNU4xoPwH","executionInfo":{"status":"ok","timestamp":1647147429729,"user_tz":-540,"elapsed":11280,"user":{"displayName":"황인규","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00970641099625056923"}},"outputId":"a715106b-275e-47ea-8567-05f8f7d30281"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.4897\n","Epoch 2/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.6414\n","Epoch 3/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.6207\n","Epoch 4/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.6897\n","Epoch 5/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.7379\n","Epoch 6/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.7517\n","Epoch 7/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.7517\n","Epoch 8/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.8069\n","Epoch 9/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.7862\n","Epoch 10/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.8069\n","Epoch 11/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.8138\n","Epoch 12/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.8000\n","Epoch 13/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.8000\n","Epoch 14/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.8069\n","Epoch 15/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.8207\n","Epoch 16/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.8000\n","Epoch 17/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.8345\n","Epoch 18/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.8345\n","Epoch 19/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.8276\n","Epoch 20/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.8621\n","Epoch 21/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.8690\n","Epoch 22/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.8483\n","Epoch 23/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.8621\n","Epoch 24/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.8897\n","Epoch 25/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.8414\n","Epoch 26/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.8621\n","Epoch 27/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.8690\n","Epoch 28/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.8828\n","Epoch 29/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.8759\n","Epoch 30/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.8759\n","Epoch 31/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.8690\n","Epoch 32/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9034\n","Epoch 33/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9034\n","Epoch 34/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.8966\n","Epoch 35/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9103\n","Epoch 36/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9103\n","Epoch 37/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9172\n","Epoch 38/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9310\n","Epoch 39/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9310\n","Epoch 40/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9379\n","Epoch 41/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9241\n","Epoch 42/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9379\n","Epoch 43/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9241\n","Epoch 44/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9379\n","Epoch 45/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9379\n","Epoch 46/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9379\n","Epoch 47/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9517\n","Epoch 48/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9448\n","Epoch 49/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9517\n","Epoch 50/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9655\n","Epoch 51/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9448\n","Epoch 52/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9586\n","Epoch 53/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9517\n","Epoch 54/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9793\n","Epoch 55/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9724\n","Epoch 56/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9931\n","Epoch 57/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9862\n","Epoch 58/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9862\n","Epoch 59/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9931\n","Epoch 60/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9793\n","Epoch 61/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9862\n","Epoch 62/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9862\n","Epoch 63/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9793\n","Epoch 64/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 1.0000\n","Epoch 65/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9931\n","Epoch 66/130\n","29/29 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9862\n","Epoch 67/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000\n","Epoch 68/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n","Epoch 69/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000\n","Epoch 70/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 1.0000\n","Epoch 71/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9931\n","Epoch 72/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000\n","Epoch 73/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9862\n","Epoch 74/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n","Epoch 75/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000\n","Epoch 76/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 77/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n","Epoch 78/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n","Epoch 79/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n","Epoch 80/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9931\n","Epoch 81/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n","Epoch 82/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 1.0000\n","Epoch 83/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n","Epoch 84/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n","Epoch 85/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n","Epoch 86/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n","Epoch 87/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n","Epoch 88/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n","Epoch 89/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 90/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n","Epoch 91/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n","Epoch 92/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n","Epoch 93/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 94/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n","Epoch 95/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 96/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 97/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 98/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n","Epoch 99/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 100/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 101/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 102/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 103/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n","Epoch 104/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 105/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 106/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 107/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 108/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 109/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 110/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 111/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 112/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 113/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 114/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 115/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 116/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 117/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 118/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 119/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 120/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 121/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 122/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 123/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 124/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 125/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 126/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 127/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 128/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 129/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 130/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n","2/2 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 0.8571\n","\n"," Test Accuracy: 0.8571\n"]}]},{"cell_type":"markdown","source":["# 4.모델 저장과 재사용\n"],"metadata":{"id":"GFo-nJ6jiOmB"}},{"cell_type":"code","source":["# # 데이터 입력\n","# from google.colab import files\n","# uploaded = files.upload()\n","# my_data = 'sonar.csv'\n","\n","\n","import tensorflow as tf\n","import pandas as pd\n","import numpy\n","\n","from keras.models import Sequential, load_model\n","from keras.layers.core import Dense\n","from sklearn.preprocessing import LabelEncoder\n","\n","# seed 값 설정\n","seed = 0\n","numpy.random.seed(seed)\n","tf.compat.v1.set_random_seed(3)\n","\n","#데이터 적용\n","df = pd.read_csv(my_data, header=None)\n","'''\n","print(df.info())\n","print(df.head())\n","'''\n","dataset = df.values\n","X = dataset[:,0:-1].astype(float)\n","Y_obj = dataset[:,60]\n","\n","e = LabelEncoder()\n","e.fit(Y_obj)\n","Y = e.transform(Y_obj)\n","# 학습셋과 테스트셋을 나눔\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n","\n","model = Sequential()\n","model.add(Dense(24,  input_dim=60, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='mean_squared_error',\n","            optimizer='adam',\n","            metrics=['accuracy'])\n","\n","model.fit(X_train, Y_train, epochs=130, batch_size=5)\n","model.save('my_model.h5')  # 모델을 컴퓨터에 저장\n","\n","del model       # 테스트를 위해 메모리 내의 모델을 삭제\n","model = load_model('my_model.h5') # 모델을 새로 불러옴\n","\n","print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))  # 불러온 모델로 테스트 실행"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKts4u8ZoPDx","executionInfo":{"status":"ok","timestamp":1647147573006,"user_tz":-540,"elapsed":12517,"user":{"displayName":"황인규","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00970641099625056923"}},"outputId":"a7309916-cf15-431a-9da8-17849df0eb88"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/130\n","29/29 [==============================] - 1s 3ms/step - loss: 0.2472 - accuracy: 0.4897\n","Epoch 2/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.6414\n","Epoch 3/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.6207\n","Epoch 4/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.6897\n","Epoch 5/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.7379\n","Epoch 6/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.7517\n","Epoch 7/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.7517\n","Epoch 8/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.8069\n","Epoch 9/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.7862\n","Epoch 10/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.8069\n","Epoch 11/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.8138\n","Epoch 12/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.8000\n","Epoch 13/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.8000\n","Epoch 14/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.8069\n","Epoch 15/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.8207\n","Epoch 16/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.8000\n","Epoch 17/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.8345\n","Epoch 18/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.8345\n","Epoch 19/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.8276\n","Epoch 20/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.8621\n","Epoch 21/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.1186 - accuracy: 0.8690\n","Epoch 22/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.8483\n","Epoch 23/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.8621\n","Epoch 24/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.8897\n","Epoch 25/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.8414\n","Epoch 26/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.8621\n","Epoch 27/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.8690\n","Epoch 28/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.8828\n","Epoch 29/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.8759\n","Epoch 30/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.8759\n","Epoch 31/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0956 - accuracy: 0.8690\n","Epoch 32/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9034\n","Epoch 33/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9034\n","Epoch 34/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.8966\n","Epoch 35/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9103\n","Epoch 36/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9103\n","Epoch 37/130\n","29/29 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9172\n","Epoch 38/130\n","29/29 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9310\n","Epoch 39/130\n","29/29 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9310\n","Epoch 40/130\n","29/29 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9379\n","Epoch 41/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9241\n","Epoch 42/130\n","29/29 [==============================] - 0s 7ms/step - loss: 0.0639 - accuracy: 0.9379\n","Epoch 43/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9241\n","Epoch 44/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9379\n","Epoch 45/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9379\n","Epoch 46/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9379\n","Epoch 47/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9517\n","Epoch 48/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9448\n","Epoch 49/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9517\n","Epoch 50/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9655\n","Epoch 51/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9448\n","Epoch 52/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9586\n","Epoch 53/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9517\n","Epoch 54/130\n","29/29 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9793\n","Epoch 55/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9724\n","Epoch 56/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9931\n","Epoch 57/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9862\n","Epoch 58/130\n","29/29 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9862\n","Epoch 59/130\n","29/29 [==============================] - 0s 7ms/step - loss: 0.0305 - accuracy: 0.9931\n","Epoch 60/130\n","29/29 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9793\n","Epoch 61/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9862\n","Epoch 62/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9862\n","Epoch 63/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9793\n","Epoch 64/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 1.0000\n","Epoch 65/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9931\n","Epoch 66/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9862\n","Epoch 67/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000\n","Epoch 68/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n","Epoch 69/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000\n","Epoch 70/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n","Epoch 71/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9931\n","Epoch 72/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n","Epoch 73/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9862\n","Epoch 74/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n","Epoch 75/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000\n","Epoch 76/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 77/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n","Epoch 78/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n","Epoch 79/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n","Epoch 80/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9931\n","Epoch 81/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n","Epoch 82/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 1.0000\n","Epoch 83/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n","Epoch 84/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n","Epoch 85/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n","Epoch 86/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n","Epoch 87/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n","Epoch 88/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n","Epoch 89/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 90/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n","Epoch 91/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n","Epoch 92/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n","Epoch 93/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 94/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n","Epoch 95/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 96/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 97/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 98/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n","Epoch 99/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 100/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 101/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 102/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 103/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n","Epoch 104/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 105/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 106/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 107/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 108/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 109/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 110/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 111/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 112/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 113/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 114/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 115/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 116/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 117/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 118/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 119/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 120/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 121/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 122/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 123/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 124/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 125/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 126/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 127/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 128/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 129/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 130/130\n","29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n","2/2 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.8571\n","\n"," Test Accuracy: 0.8571\n"]}]},{"cell_type":"markdown","source":["# 5.k겹 교차 검증"],"metadata":{"id":"LF-7WV0kiQDF"}},{"cell_type":"markdown","source":["- 데이터가 충분하지 않은 경우 문제가 됨\n","- k겹 교차 검증 :\n","  - 데이터셋을 여러 개로 나누어 하나씩 테스트셋으로 사용하고 나머지를 모두 합해서 학습셋으로 사용하는 방법"],"metadata":{"id":"8LjtjUzjpcm1"}},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlfX0dS4g9Ey","executionInfo":{"status":"ok","timestamp":1647148031970,"user_tz":-540,"elapsed":114818,"user":{"displayName":"황인규","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00970641099625056923"}},"outputId":"057867b0-cca6-4661-cfa7-ef9ced517883"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","38/38 [==============================] - 1s 3ms/step - loss: 0.2366 - accuracy: 0.5348\n","Epoch 2/100\n","38/38 [==============================] - 0s 5ms/step - loss: 0.2258 - accuracy: 0.5455\n","Epoch 3/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.5775\n","Epoch 4/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.6791\n","Epoch 5/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.6738\n","Epoch 6/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.7166\n","Epoch 7/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.7005\n","Epoch 8/100\n","38/38 [==============================] - 0s 5ms/step - loss: 0.1896 - accuracy: 0.7968\n","Epoch 9/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.7487\n","Epoch 10/100\n","38/38 [==============================] - 0s 7ms/step - loss: 0.1749 - accuracy: 0.7968\n","Epoch 11/100\n","38/38 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.8182\n","Epoch 12/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.7914\n","Epoch 13/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.8128\n","Epoch 14/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.8235\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.7968\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.7968\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.8128\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.8342\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.8182\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.7861\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.8235\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.8396\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.8396\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.8717\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.8717\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.8717\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.8930\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.8770\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.8824\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.8877\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.8663\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.8930\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.8930\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.8717\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.8877\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9037\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9144\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9305\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9198\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.8984\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9037\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9198\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9305\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9144\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9144\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9358\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9091\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9198\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9251\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9305\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9144\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9305\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9465\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9519\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9251\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9519\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9465\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9251\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9412\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9572\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9198\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9465\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9465\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9626\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9626\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9626\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9412\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9572\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9626\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9786\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9572\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9733\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9626\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9840\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9733\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9786\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9786\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9786\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9786\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9840\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9840\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9733\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9786\n","Epoch 84/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9786\n","Epoch 85/100\n","38/38 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9840\n","Epoch 86/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9786\n","Epoch 87/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9786\n","Epoch 88/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9840\n","Epoch 89/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9893\n","Epoch 90/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9893\n","Epoch 91/100\n","38/38 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9786\n","Epoch 92/100\n","38/38 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9893\n","Epoch 93/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9893\n","Epoch 94/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9893\n","Epoch 95/100\n","38/38 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9840\n","Epoch 96/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9893\n","Epoch 97/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9893\n","Epoch 98/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9947\n","Epoch 99/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9840\n","Epoch 100/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9893\n","1/1 [==============================] - 0s 108ms/step - loss: 0.0816 - accuracy: 0.9524\n","Epoch 1/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.5455\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.5615\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.5401\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.6898\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.7112\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.7540\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.7433\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.8075\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.8235\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.7968\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.8396\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.8449\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.8021\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.8396\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.8342\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.8610\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.8396\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.8342\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.8449\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.8342\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.8182\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.8289\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.8449\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.8396\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.8449\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.8610\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.8396\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.8289\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.8396\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.8556\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.8556\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.8449\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.8396\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.8556\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.8342\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.8770\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.8717\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.8824\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.8717\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.8877\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.8877\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.8930\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.8824\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.8877\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.8717\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.8877\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.8556\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.8877\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9091\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.8824\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.8877\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.8824\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.8930\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.9091\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9144\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.8877\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.8930\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9144\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.8877\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.8984\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.8877\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9091\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9144\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9198\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.8930\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.8930\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9037\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9144\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9251\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9144\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9251\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9198\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9305\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9358\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9305\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9412\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9198\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9358\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9519\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9358\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9412\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9412\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9358\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9358\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9144\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9519\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9519\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9465\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9519\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9412\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9572\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9519\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9465\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9412\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9465\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9465\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9519\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9465\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9626\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9572\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0b984deb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 116ms/step - loss: 0.2670 - accuracy: 0.6667\n","Epoch 1/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.4866\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.5348\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.5668\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.6631\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.7112\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.7219\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.7754\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.7754\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.7914\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 0.8021\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.7807\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.8182\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.8128\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.8235\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.7914\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.8075\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.8235\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.8556\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.8342\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.8503\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.8449\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.8449\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.8449\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.8289\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.8610\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.8663\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.8663\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.8770\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.8663\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.8877\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.8877\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.8930\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.8984\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.8824\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.8984\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9144\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9037\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9358\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9358\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9198\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9412\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9465\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9305\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9305\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9358\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9251\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9305\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9519\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9465\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9519\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9412\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9626\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9465\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9626\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9626\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9572\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9572\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9626\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9679\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9679\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9733\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9679\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9679\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9679\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9626\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9733\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9733\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9733\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9679\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9786\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9786\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9786\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9733\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9840\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9733\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9786\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9840\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9733\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9840\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9840\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9840\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9786\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9893\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9840\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9893\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9893\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9893\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9893\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9947\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9840\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9947\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9947\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9947\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9947\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9947\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9893\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9893\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9947\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9947\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9947\n","WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0b98293b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 118ms/step - loss: 0.1697 - accuracy: 0.7619\n","Epoch 1/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.4759\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.5348\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.5455\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.6845\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.7166\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.7219\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.7487\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7647\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.7701\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.7594\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.7807\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.7914\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.7807\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.7914\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.8021\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.8128\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.8396\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.8075\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.8449\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.8128\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.8235\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.8235\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.8556\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.8342\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.8503\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.8610\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.8770\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.8556\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.8396\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.8930\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.8610\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.8824\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.8824\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.8877\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.8824\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.8984\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.8824\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.8770\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.8984\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9091\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9091\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.8930\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9091\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9091\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9091\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.8984\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9037\n","Epoch 48/100\n","38/38 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9091\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9091\n","Epoch 50/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9091\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9144\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9198\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9198\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9358\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9037\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9305\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9144\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9091\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9358\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9412\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9305\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9305\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9305\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9358\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9358\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9198\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9358\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9412\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9305\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9358\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9305\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9519\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9144\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9412\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9519\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9679\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9465\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9519\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9519\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9626\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9679\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9572\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9733\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9465\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9626\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9733\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9626\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9572\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9786\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9733\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9572\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9626\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9679\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9679\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9626\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9679\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9840\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9786\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9733\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9840\n","1/1 [==============================] - 0s 109ms/step - loss: 0.0316 - accuracy: 0.9524\n","Epoch 1/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.5615\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.6364\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.6898\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.6845\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.7594\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.7914\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7807\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.8021\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.8182\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.7968\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.8342\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.8235\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.8396\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.8182\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.8342\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.8289\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.8128\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.8503\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.8556\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.8610\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.8342\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.8342\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.8663\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.8556\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.8930\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.8930\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.8770\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.8824\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.8610\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.8930\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.8877\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9037\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.8877\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9091\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9091\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9144\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9198\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9037\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9358\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9091\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9198\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9412\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9198\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.8984\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9305\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9412\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9144\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9251\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9358\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9358\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9465\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9251\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9465\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9465\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9305\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9519\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9305\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9358\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9519\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9305\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9305\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9519\n","Epoch 63/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9358\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9412\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9465\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9412\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9519\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9412\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9519\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9626\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9465\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9519\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9412\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9679\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9572\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9626\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9572\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9626\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9679\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9626\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9412\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9572\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9626\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9733\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9626\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9786\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9733\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9733\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9626\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9786\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9733\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9733\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9786\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9679\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9840\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9840\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9840\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9840\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9733\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9893\n","1/1 [==============================] - 0s 107ms/step - loss: 0.2419 - accuracy: 0.7143\n","Epoch 1/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.5936\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.6310\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.6524\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.6738\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.7005\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.7219\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.7112\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.7433\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.7326\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.7647\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.8021\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.7968\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.7914\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.7861\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.7914\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.8235\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.8021\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.8342\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.8289\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.8396\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.8021\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.8289\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.8449\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.8289\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.8503\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.8610\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.8663\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.8610\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.8717\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.8824\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.8449\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.8770\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.8503\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.8770\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.8824\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.8930\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.8824\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.8984\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.8984\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.8930\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.8984\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.8984\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9091\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.8824\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9144\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9091\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.8984\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9251\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9251\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9037\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9251\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9358\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9251\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9358\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9305\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9358\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9412\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9305\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9412\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9358\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9465\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9412\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9572\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9465\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9572\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9519\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9519\n","Epoch 68/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9412\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9572\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9519\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9412\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9733\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9305\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9572\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9572\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9626\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9733\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9679\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9786\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9679\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9733\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9679\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9733\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9679\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9626\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9733\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9733\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9733\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9840\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9786\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9786\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9733\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9786\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9786\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9733\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9733\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9840\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9947\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9893\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9893\n","1/1 [==============================] - 0s 110ms/step - loss: 0.1021 - accuracy: 0.9048\n","Epoch 1/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.5936\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.6524\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.6738\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.6845\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.7112\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.7540\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.7647\n","Epoch 8/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.7754\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.7914\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.8182\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.7861\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.8128\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.8128\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.7968\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.8235\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.8182\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.8021\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.8235\n","Epoch 19/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.8289\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.8128\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.8556\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.8342\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.8396\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.8396\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.8663\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.8610\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.8717\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.8824\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.8663\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.8770\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.8663\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.8556\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.8503\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.8663\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.8930\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.8877\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.8824\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.8877\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9037\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9037\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.8984\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9144\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.8877\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.8930\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9091\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9305\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.8930\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9198\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9198\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9198\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9144\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9358\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9358\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9412\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9358\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9412\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9465\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9358\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9519\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9572\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9465\n","Epoch 62/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9519\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9572\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9412\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9626\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9679\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9626\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9626\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9679\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9626\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9786\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9733\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9626\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9733\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9679\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9679\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9733\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9786\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9786\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9733\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9840\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9786\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9733\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9733\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9893\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9840\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9840\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9893\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9947\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9840\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9893\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9733\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9786\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9893\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9840\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9947\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9947\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9840\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9840\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9840\n","1/1 [==============================] - 0s 123ms/step - loss: 0.1829 - accuracy: 0.7143\n","Epoch 1/100\n","38/38 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.5187\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.6578\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.6631\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.7005\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.7273\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.7112\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.7487\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.7219\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.7326\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.7594\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.7487\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.7807\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.7754\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.7968\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.7914\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.7807\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.7807\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.8182\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.7968\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.7914\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.7807\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.7968\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.8235\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.8182\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.8235\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.8289\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.8128\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.8289\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.8075\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.8396\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.8396\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.8396\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.8396\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.8396\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.8663\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.8610\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.8770\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.8770\n","Epoch 39/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.8663\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.8770\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.8770\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.8877\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.8984\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.8877\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.8930\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9037\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.8930\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9091\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9091\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9144\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9144\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.8984\n","Epoch 53/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9251\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9251\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9144\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9412\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9358\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9305\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9412\n","Epoch 60/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9358\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9412\n","Epoch 62/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9305\n","Epoch 63/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9358\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9412\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9519\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9412\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9465\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9572\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9519\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9572\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9519\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9626\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9572\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9679\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9679\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9626\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9626\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9733\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9733\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9840\n","Epoch 81/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9893\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9786\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9893\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9893\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9733\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9840\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9893\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9786\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9840\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9786\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9947\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9893\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9947\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9893\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9786\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9840\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9893\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9947\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9947\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9893\n","1/1 [==============================] - 0s 111ms/step - loss: 0.1152 - accuracy: 0.8571\n","Epoch 1/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.6064\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.6702\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.7021\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.6915\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.7394\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.7606\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.7500\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.7766\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.7500\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.7766\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.8138\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.7872\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.8032\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.8191\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.7926\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.8351\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.8138\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.8191\n","Epoch 19/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.8457\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.8511\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.8351\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.8245\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.8511\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.8830\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.8777\n","Epoch 26/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.8564\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.8830\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.8723\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.8670\n","Epoch 30/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.8777\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.8830\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.8936\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.8989\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.8989\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.8883\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9149\n","Epoch 37/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9149\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9096\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9202\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9255\n","Epoch 41/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.9096\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9362\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9255\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9202\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.8883\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9255\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9149\n","Epoch 48/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9362\n","Epoch 49/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9309\n","Epoch 50/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9096\n","Epoch 51/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9521\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9574\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9574\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9574\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9521\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9521\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9628\n","Epoch 58/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9415\n","Epoch 59/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9468\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9521\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9468\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9521\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9628\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9574\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9521\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9628\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9628\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9309\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9681\n","Epoch 70/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9681\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9628\n","Epoch 72/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9681\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9628\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9574\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9681\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9521\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9681\n","Epoch 78/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9681\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9628\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9681\n","Epoch 81/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9734\n","Epoch 82/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9681\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9681\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9681\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9681\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9681\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9681\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9681\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9681\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9681\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9681\n","Epoch 92/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9734\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9628\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9681\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9734\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9628\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9787\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9787\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9734\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9787\n","1/1 [==============================] - 0s 107ms/step - loss: 0.1785 - accuracy: 0.7500\n","Epoch 1/100\n","38/38 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.4840\n","Epoch 2/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.5851\n","Epoch 3/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.6702\n","Epoch 4/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.6809\n","Epoch 5/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.7287\n","Epoch 6/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.6862\n","Epoch 7/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.7128\n","Epoch 8/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.7447\n","Epoch 9/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.7713\n","Epoch 10/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7713\n","Epoch 11/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.8138\n","Epoch 12/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.8138\n","Epoch 13/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.8032\n","Epoch 14/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.7819\n","Epoch 15/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.8032\n","Epoch 16/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.8032\n","Epoch 17/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.7979\n","Epoch 18/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.8351\n","Epoch 19/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.8457\n","Epoch 20/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.8085\n","Epoch 21/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.8191\n","Epoch 22/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.8245\n","Epoch 23/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.8404\n","Epoch 24/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.8511\n","Epoch 25/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.8670\n","Epoch 26/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.8617\n","Epoch 27/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.8564\n","Epoch 28/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.8617\n","Epoch 29/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.8670\n","Epoch 30/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.8830\n","Epoch 31/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.8723\n","Epoch 32/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.8723\n","Epoch 33/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.8723\n","Epoch 34/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.8830\n","Epoch 35/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.8777\n","Epoch 36/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.8883\n","Epoch 37/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.8989\n","Epoch 38/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9043\n","Epoch 39/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9043\n","Epoch 40/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9096\n","Epoch 41/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.8883\n","Epoch 42/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9043\n","Epoch 43/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0879 - accuracy: 0.9149\n","Epoch 44/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.8989\n","Epoch 45/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.8883\n","Epoch 46/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9149\n","Epoch 47/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.8936\n","Epoch 48/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.8989\n","Epoch 49/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9202\n","Epoch 50/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9202\n","Epoch 51/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9149\n","Epoch 52/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.8883\n","Epoch 53/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9096\n","Epoch 54/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9202\n","Epoch 55/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.8936\n","Epoch 56/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9255\n","Epoch 57/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9043\n","Epoch 58/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9309\n","Epoch 59/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9309\n","Epoch 60/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9362\n","Epoch 61/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9362\n","Epoch 62/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9309\n","Epoch 63/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9096\n","Epoch 64/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9309\n","Epoch 65/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9415\n","Epoch 66/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9415\n","Epoch 67/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9362\n","Epoch 68/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9468\n","Epoch 69/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9362\n","Epoch 70/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9362\n","Epoch 71/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9309\n","Epoch 72/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9362\n","Epoch 73/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9415\n","Epoch 74/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9574\n","Epoch 75/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9309\n","Epoch 76/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9362\n","Epoch 77/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9362\n","Epoch 78/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9521\n","Epoch 79/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9521\n","Epoch 80/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9468\n","Epoch 81/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9415\n","Epoch 82/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9574\n","Epoch 83/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9574\n","Epoch 84/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9628\n","Epoch 85/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9681\n","Epoch 86/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9628\n","Epoch 87/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9574\n","Epoch 88/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9521\n","Epoch 89/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9628\n","Epoch 90/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9628\n","Epoch 91/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9734\n","Epoch 92/100\n","38/38 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9521\n","Epoch 93/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9681\n","Epoch 94/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9734\n","Epoch 95/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9628\n","Epoch 96/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9787\n","Epoch 97/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9521\n","Epoch 98/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9734\n","Epoch 99/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9787\n","Epoch 100/100\n","38/38 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9681\n","1/1 [==============================] - 0s 109ms/step - loss: 0.1160 - accuracy: 0.8500\n","\n"," 10 fold accuracy: ['0.9524', '0.6667', '0.7619', '0.9524', '0.7143', '0.9048', '0.7143', '0.8571', '0.7500', '0.8500']\n"]}],"source":["# # 데이터 입력\n","# from google.colab import files\n","# uploaded = files.upload()\n","# my_data = 'sonar.csv'\n","\n","import tensorflow as tf\n","import pandas as pd\n","import numpy\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","\n","# seed 값 설정\n","seed = 42\n","numpy.random.seed(seed)\n","tf.compat.v1.set_random_seed(42)\n","\n","# 데이터 적용\n","df = pd.read_csv(my_data, header=None)\n","\n","dataset = df.values\n","X = dataset[:,0:60].astype(float)\n","Y_obj = dataset[:,60]\n","\n","e = LabelEncoder()\n","e.fit(Y_obj)\n","Y = e.transform(Y_obj)\n","\n","# 10개의 파일로 쪼갬\n","n_fold = 10\n","skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n","\n","# 빈 accuracy 배열\n","accuracy = []\n","\n","# 모델의 설정, 컴파일, 실행\n","for train, test in skf.split(X, Y):\n","    model = Sequential()\n","    model.add(Dense(24, input_dim=60, activation='relu'))\n","    model.add(Dense(10, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    model.compile(loss='mean_squared_error',\n","                  optimizer='adam',\n","                  metrics=['accuracy'])\n","    model.fit(X[train], Y[train], epochs=100, batch_size=5)\n","    k_accuracy = \"%.4f\" % (model.evaluate(X[test], Y[test])[1])\n","    accuracy.append(k_accuracy)\n","\n","# 결과 출력\n","print(\"\\n %.f fold accuracy:\" % n_fold, accuracy)"]}]}